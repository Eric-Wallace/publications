

This section details \name{}:\footnote{
\let\hyper@linkurl\saved@hyper@linkurl
Code available at \url{https://github.com/Foroughp/ALTO-ACL-2016}
\NoHyper } a framework for assigning labels to
documents that uses both global and local knowledge to help users
create and assign document labels. We explain how
\name{} uses topic models to aid label induction and document
labeling. We then use active learning to direct user attention and
speed document labeling.











\paragraph{Topic Models}

Topic models~\cite{Blei-03} automatically induce structure from a text
corpus.  Given a corpus and a constant $K$ for the number of topics,
topic models output (i) a distribution over words for each topic $k$
($\phi_{k,w}$) and (ii) a distribution over topics for each document
($\theta_{d,k}$).  Each topic's most probable words and associated
documents can help a user understand what the collection is
about. Table~\ref{tab:doc_topics} shows examples of topics and their
highest associated documents from our corpus of \abr{us} congressional
bills.

Our hypothesis is that showing documents grouped by topics will be more effective
than having the user wade through an undifferentiated list of random documents and
\emph{mentally sort the major themes themselves}.













\paragraph{Active Learning}

Active learning~\cite{settles2012active} directs users' attention to
the examples that would be most useful to label when training a
classifier.  When user time is scarce, active learning builds a
more effective training set than random labeling: uncertainty
sampling~\cite{lewis1994sequential} or query by
committee~\cite{seung1992query} direct users to the most useful
documents to label.

In contrast to topic models, active learning provides local
information: this is the individual document you should pay attention
to.  Our hypothesis is that active learning, when used as a
\emph{preference function} to direct the users to documents most
beneficial to label, will not only be more effective than randomly
selecting documents but will also \emph{complement} the global
information provided by topic models. Section~\ref{sub:AL} describes
the preference functions for the experimental conditions.








\begin{table}[t!]
\small
\begin{tabular}{ p{2.4cm}  p{4.3cm} }
    \hline
    Topic words & Document Title
    \tabularnewline \hline \hline

metropolitan, carrier, rail, freight, passenger, driver, airport, traffic, transit, vehicles &
A bill to improve the safety of motorcoaches, and for other purposes.
    \tabularnewline
    \hline
	violence, sexual, criminal, assault, offense, victims, domestic, crime, abuse, trafficking
		& A bill to provide criminal penalties for stalking.
\tabularnewline
\hline
agricultural, farm, agriculture, rural, producer, dairy, crop, producers, commodity, nutrition
		& To amend the Federal Crop Insurance Act to extend certain supplemental agricultural disaster assistance programs through fiscal year 2017, and for other purposes.
\tabularnewline
\hline
\end{tabular}
\caption{
  Given a dataset---in this case, the \abr{us} congressional bills
  dataset---topics are automatically discovered sorted lists of terms that summarize segments of a document collection.  Topics also
  are  associated with documents.  These topics give users a
  sense of documents' main themes and help users create high-quality labels.}
\label{tab:doc_topics}
\end{table}
